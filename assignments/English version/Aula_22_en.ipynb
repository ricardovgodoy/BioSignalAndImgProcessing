{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!# --- Required Imports ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data, img_as_float, img_as_ubyte, exposure, util, filters\n",
    "from scipy import ndimage\n",
    "from numpy.fft import fft2, ifft2, fftshift, ifftshift\n",
    "import cv2 # Used in example 5.6 for cv2.line\n",
    "\n",
    "# --- Load Medical Image and Define Global Variables ---\n",
    "try:\n",
    "    brain_volume = data.brain()\n",
    "    if brain_volume.ndim == 3:\n",
    "        slice_index = brain_volume.shape[0] // 2\n",
    "        image_gray_orig_c5 = brain_volume[slice_index, :, :]\n",
    "    elif brain_volume.ndim == 2:\n",
    "        image_gray_orig_c5 = brain_volume\n",
    "        slice_index = \"N/A (2D Image)\"\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected 'brain' image format.\")\n",
    "    print(f\"'brain' image (slice {slice_index if brain_volume.ndim == 3 else ''}) loaded for Ch. 5.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading 'brain': {e}. Using 'camera' as fallback.\")\n",
    "    image_gray_orig_c5 = data.camera()\n",
    "\n",
    "image_float_c5 = img_as_float(image_gray_orig_c5.copy())\n",
    "M_c5, N_c5 = image_float_c5.shape # Original dimensions\n",
    "P_c5, Q_c5 = 2*M_c5, 2*N_c5     # Padded dimensions\n",
    "\n",
    "# --- Helper Function for IDFT, Extraction, and Rescaling ---\n",
    "def idft_process_extract(G_centralizado, P_img, Q_img, M_orig, N_orig):\n",
    "    G_canto_dc = ifftshift(G_centralizado)\n",
    "    img_padded_spatial = ifft2(G_canto_dc).real\n",
    "    img_final = img_padded_spatial[0:M_orig, 0:N_orig]\n",
    "    return exposure.rescale_intensity(img_final, out_range=(0,1))\n",
    "\n",
    "# --- Helper Plot Function  ---\n",
    "def plot_images_c5(images, titles, cmaps=None, rows=1, cols=None, figsize=(15,5)):\n",
    "    num_images = len(images)\n",
    "    if cols is None:\n",
    "        cols = (num_images + rows - 1) // rows\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize, squeeze=False)\n",
    "    axes_flat = axes.ravel()\n",
    "    if cmaps is None: cmaps_list = ['gray'] * num_images\n",
    "    elif isinstance(cmaps, str): cmaps_list = [cmaps] * num_images\n",
    "    else:\n",
    "        cmaps_list = list(cmaps)\n",
    "        if len(cmaps_list) < num_images: cmaps_list.extend(['gray']*(num_images-len(cmaps_list)))\n",
    "    for i in range(len(axes_flat)):\n",
    "        if i < num_images:\n",
    "            img, title, cmap_val = images[i], titles[i], cmaps_list[i] # Renamed cmap to cmap_val\n",
    "            axes_flat[i].imshow(img, cmap=cmap_val if img.ndim==2 else None); axes_flat[i].set_title(title); axes_flat[i].axis('off')\n",
    "        else: axes_flat[i].axis('off')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "L_mov_c5 = 21\n",
    "psf_movimento_c5 = np.zeros((L_mov_c5, L_mov_c5), dtype=float)\n",
    "psf_movimento_c5[L_mov_c5//2, :] = 1.0\n",
    "psf_movimento_c5 /= np.sum(psf_movimento_c5)\n",
    "\n",
    "psf_movimento_padded_rolled_c5 = np.zeros((P_c5, Q_c5), dtype=float)\n",
    "r_offset_c5, c_offset_c5 = L_mov_c5//2, L_mov_c5//2\n",
    "for r_psf in range(L_mov_c5):\n",
    "    for c_psf in range(L_mov_c5):\n",
    "        idx_r_pad = (r_psf - r_offset_c5 + P_c5) % P_c5\n",
    "        idx_c_pad = (c_psf - c_offset_c5 + Q_c5) % Q_c5\n",
    "        psf_movimento_padded_rolled_c5[idx_r_pad, idx_c_pad] = psf_movimento_c5[r_psf, c_psf]\n",
    "H_movimento_nao_centralizado_c5 = fft2(psf_movimento_padded_rolled_c5) # DC at corner\n",
    "\n",
    "fp_para_degradacao_c5 = np.zeros((P_c5, Q_c5))\n",
    "fp_para_degradacao_c5[0:M_c5, 0:N_c5] = image_float_c5\n",
    "F_img_original_padded_nao_centralizado_c5 = fft2(fp_para_degradacao_c5)\n",
    "\n",
    "G_degradada_mov_nao_centralizado_c5 = F_img_original_padded_nao_centralizado_c5 * H_movimento_nao_centralizado_c5\n",
    "img_degradada_mov_padded_c5 = ifft2(G_degradada_mov_nao_centralizado_c5).real\n",
    "img_degradada_mov_c5 = exposure.rescale_intensity(img_degradada_mov_padded_c5[0:M_c5, 0:N_c5], out_range=(0,1))\n",
    "\n",
    "\n",
    "\n",
    "# --- Required Imports ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data, img_as_float, img_as_ubyte, exposure, util, filters\n",
    "from scipy import ndimage\n",
    "from numpy.fft import fft2, ifft2, fftshift, ifftshift\n",
    "import cv2 # Used in example 5.6 for cv2.line\n",
    "\n",
    "# --- Load Medical Image and Define Global Variables ---\n",
    "try:\n",
    "    brain_volume = data.brain()\n",
    "    if brain_volume.ndim == 3:\n",
    "        slice_index = brain_volume.shape[0] // 2\n",
    "        image_gray_orig_c5 = brain_volume[slice_index, :, :]\n",
    "    elif brain_volume.ndim == 2:\n",
    "        image_gray_orig_c5 = brain_volume\n",
    "        slice_index = \"N/A (2D Image)\"\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected 'brain' image format.\")\n",
    "    print(f\"'brain' image (slice {slice_index if brain_volume.ndim == 3 else ''}) loaded for Ch. 5.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading 'brain': {e}. Using 'camera' as fallback.\")\n",
    "    image_gray_orig_c5 = data.camera()\n",
    "\n",
    "image_float_c5 = img_as_float(image_gray_orig_c5.copy())\n",
    "M_c5, N_c5 = image_float_c5.shape # Original dimensions\n",
    "P_c5, Q_c5 = 2*M_c5, 2*N_c5     # Padded dimensions\n",
    "\n",
    "# --- Helper Function for IDFT, Extraction, and Rescaling ---\n",
    "def idft_process_extract(G_centralizado, P_img, Q_img, M_orig, N_orig):\n",
    "    G_canto_dc = ifftshift(G_centralizado)\n",
    "    img_padded_spatial = ifft2(G_canto_dc).real\n",
    "    img_final = img_padded_spatial[0:M_orig, 0:N_orig]\n",
    "    return exposure.rescale_intensity(img_final, out_range=(0,1))\n",
    "\n",
    "# --- Helper Plot Function (CORRIGIDA PARA USAR plot_images_c5 consistentemente) ---\n",
    "def plot_images_c5(images, titles, cmaps=None, rows=1, cols=None, figsize=(15,5)):\n",
    "    num_images = len(images)\n",
    "    if cols is None:\n",
    "        cols = (num_images + rows - 1) // rows\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize, squeeze=False)\n",
    "    axes_flat = axes.ravel()\n",
    "    if cmaps is None: cmaps_list = ['gray'] * num_images\n",
    "    elif isinstance(cmaps, str): cmaps_list = [cmaps] * num_images\n",
    "    else:\n",
    "        cmaps_list = list(cmaps)\n",
    "        if len(cmaps_list) < num_images: cmaps_list.extend(['gray']*(num_images-len(cmaps_list)))\n",
    "    for i in range(len(axes_flat)):\n",
    "        if i < num_images:\n",
    "            img, title, cmap_val = images[i], titles[i], cmaps_list[i] # Renamed cmap to cmap_val\n",
    "            axes_flat[i].imshow(img, cmap=cmap_val if img.ndim==2 else None); axes_flat[i].set_title(title); axes_flat[i].axis('off')\n",
    "        else: axes_flat[i].axis('off')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Generate the motion-degraded image and H_motion (from example 5.6)\n",
    "# para que os exemplos 5.7, 5.8, 5.9 possam rodar\n",
    "\n",
    "L_mov_c5 = 21\n",
    "psf_movimento_c5 = np.zeros((L_mov_c5, L_mov_c5), dtype=float)\n",
    "psf_movimento_c5[L_mov_c5//2, :] = 1.0\n",
    "psf_movimento_c5 /= np.sum(psf_movimento_c5)\n",
    "\n",
    "psf_movimento_padded_rolled_c5 = np.zeros((P_c5, Q_c5), dtype=float)\n",
    "r_offset_c5, c_offset_c5 = L_mov_c5//2, L_mov_c5//2\n",
    "for r_psf in range(L_mov_c5):\n",
    "    for c_psf in range(L_mov_c5):\n",
    "        idx_r_pad = (r_psf - r_offset_c5 + P_c5) % P_c5\n",
    "        idx_c_pad = (c_psf - c_offset_c5 + Q_c5) % Q_c5\n",
    "        psf_movimento_padded_rolled_c5[idx_r_pad, idx_c_pad] = psf_movimento_c5[r_psf, c_psf]\n",
    "H_movimento_nao_centralizado_c5 = fft2(psf_movimento_padded_rolled_c5) # DC at corner\n",
    "\n",
    "fp_para_degradacao_c5 = np.zeros((P_c5, Q_c5))\n",
    "fp_para_degradacao_c5[0:M_c5, 0:N_c5] = image_float_c5\n",
    "F_img_original_padded_nao_centralizado_c5 = fft2(fp_para_degradacao_c5)\n",
    "\n",
    "G_degradada_mov_nao_centralizado_c5 = F_img_original_padded_nao_centralizado_c5 * H_movimento_nao_centralizado_c5\n",
    "img_degradada_mov_padded_c5 = ifft2(G_degradada_mov_nao_centralizado_c5).real\n",
    "img_degradada_mov_c5 = exposure.rescale_intensity(img_degradada_mov_padded_c5[0:M_c5, 0:N_c5], out_range=(0,1))\n",
    "\n",
    "\n",
    "# --- Required Imports ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data, img_as_float, img_as_ubyte, transform, exposure, util, filters, morphology\n",
    "from scipy import ndimage\n",
    "from numpy.fft import fft2, ifft2, fftshift, ifftshift # For practice Block 4\n",
    "import time\n",
    "import cv2 # To draw circles in Task 1.3\n",
    "\n",
    "# --- Helper Function to Plot Multiple Images ---\n",
    "def plot_images(images, titles, cmaps=None, rows=1, cols=None, figsize=(15,5)):\n",
    "    num_images = len(images)\n",
    "    if cols is None:\n",
    "        cols = (num_images + rows - 1) // rows\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize, squeeze=False) # squeeze=False ensures axes is always 2D\n",
    "\n",
    "    axes_flat = axes.ravel()\n",
    "\n",
    "    if cmaps is None:\n",
    "        cmaps_list = ['gray'] * num_images\n",
    "    elif isinstance(cmaps, str):\n",
    "        cmaps_list = [cmaps] * num_images\n",
    "    else:\n",
    "        cmaps_list = list(cmaps)\n",
    "        if len(cmaps_list) < num_images:\n",
    "            cmaps_list.extend(['gray'] * (num_images - len(cmaps_list)))\n",
    "\n",
    "    for i in range(len(axes_flat)):\n",
    "        if i < num_images:\n",
    "            img = images[i]\n",
    "            title = titles[i]\n",
    "            current_cmap = cmaps_list[i]\n",
    "\n",
    "            axes_flat[i].imshow(img, cmap=current_cmap if img.ndim == 2 else None)\n",
    "            axes_flat[i].set_title(title)\n",
    "            axes_flat[i].axis('off')\n",
    "        else:\n",
    "            axes_flat[i].axis('off') # Desliga eixos extras\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Load Medical Image ---\n",
    "try:\n",
    "    brain_volume = data.brain()\n",
    "    if brain_volume.ndim == 3:\n",
    "        slice_index = brain_volume.shape[0] // 2\n",
    "        image_gray_orig = brain_volume[slice_index, :, :]\n",
    "    elif brain_volume.ndim == 2:\n",
    "        image_gray_orig = brain_volume\n",
    "        slice_index = \"N/A (2D Image)\"\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected 'brain' image format.\")\n",
    "    print(f\"'brain' image (slice {slice_index if brain_volume.ndim == 3 else ''}) loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading 'brain': {e}. Using 'camera' as fallback.\")\n",
    "    image_gray_orig = data.camera()\n",
    "\n",
    "# ESTAS SÃO AS VARIÁVEIS GLOBAIS PARA A PRÁTICA\n",
    "image_float_g = img_as_float(image_gray_orig.copy())\n",
    "image_ubyte_g = img_as_ubyte(image_gray_orig.copy())\n",
    "M_g, N_g = image_float_g.shape # Global dimensions for the practice\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87dh1j7BH-KB",
    "outputId": "f5ab4aba-a489-406b-ed81-8d771ca4173f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Edge Detection with Sobel (Practice)\n"
   ],
   "metadata": {
    "id": "meZ1tRfZHJTl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Objective: Apply the Sobel operator to detect edges in a medical image.\n"
   ],
   "metadata": {
    "id": "0yWMWIIWHOAs"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How the Code Works:\n",
    "\n",
    "1. Load Image: Uses `image_float_g` (brain image).\n",
    "2. Sobel Filter:\n",
    "   * `filters.sobel_h(image_float_g)`: Computes the horizontal component (related to vertical edges).\n",
    "   * `filters.sobel_v(image_float_g)`: Computes the vertical component (related to horizontal edges).\n",
    "   * `filters.sobel(image_float_g)`: Computes gradient magnitude.\n",
    "3. Thresholding: Applies a threshold to Sobel magnitude to produce a binary edge image.\n"
   ],
   "metadata": {
    "id": "CDXONQj_HQV1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvIFHwEADICF",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 991
    },
    "outputId": "d956c965-3618-4b22-e1fc-01b23a241168"
   },
   "outputs": [],
   "source": [
    "# Python Example: Edge Detection with Sobel\n",
    "print(\"\\n--- Practical Example: Edge Detection with Sobel ---\")\n",
    "from skimage import filters # filters was already imported, but kept here for clarity\n",
    "\n",
    "# Apply Sobel\n",
    "sob_h = filters.sobel_h(image_float_g) # Horizontal component g_x\n",
    "sob_v = filters.sobel_v(image_float_g) # Vertical component g_y\n",
    "mag_sobel = filters.sobel(image_float_g) # Gradient magnitude\n",
    "\n",
    "# Threshold the magnitude to obtain a binary edge image\n",
    "limiar_sobel_val = 0.05 # Adjust this value\n",
    "bordas_sobel = mag_sobel > limiar_sobel_val\n",
    "\n",
    "plot_images_c5([image_float_g, sob_h, sob_v, mag_sobel, bordas_sobel],\n",
    "               [\"Original\", \"Sobel Gx\", \"Sobel Gy\", \"Sobel Magnitude\", f\"Sobel Edges (T={limiar_sobel_val})\"],\n",
    "               rows=2, cols=3, figsize=(15,10),\n",
    "               cmaps=['gray','gray','gray','viridis','gray']) # Use viridis for magnitude\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interpreting the Results (Sobel):\n",
    "\n",
    "* Original: Input image.\n",
    "* Sobel Gx: Highlights vertical edges.\n",
    "* Sobel Gy: Highlights horizontal edges.\n",
    "* Sobel Magnitude: Overall edge strength map.\n",
    "* Thresholded Edges: Binary edge image after thresholding.\n"
   ],
   "metadata": {
    "id": "L55CvdJZrVjY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Short Exercise (Edge Detection):\n",
    "\n",
    "* Change `limiar_sobel_val` to `0.02`, `0.1`, and `0.2`. What happens to the number of detected edges? How does sensitivity change?\n"
   ],
   "metadata": {
    "id": "Del5GKikrd11"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Edge Detection with Canny (Practice)\n",
    "\n",
    "Objective: Apply Canny edge detection and observe the effect of its parameters.\n"
   ],
   "metadata": {
    "id": "vDNVTmwq3guD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How the Code Works:\n",
    "\n",
    "1. `feature.canny(image_float_g, sigma=..., low_threshold=..., high_threshold=...)`\n",
    "   * `image_float_g`: input image.\n",
    "   * `sigma`: Gaussian smoothing before gradient computation.\n",
    "   * `low_threshold`, `high_threshold`: hysteresis thresholds for edge linking.\n",
    "2. Visualization: Displays original image and Canny output.\n"
   ],
   "metadata": {
    "id": "w3GVjm4q3pHr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Python Example: Edge Detection with Canny - FIXED\n",
    "print(\"\\n--- Practical Example: Edge Detection with Canny ---\")\n",
    "from skimage import feature # CORRECT import for Canny\n",
    "\n",
    "# Canny parameters (these may need tuning for your image)\n",
    "sigma_canny_c10 = 1.5 # Slightly increase sigma for more initial smoothing\n",
    "low_thresh_canny_c10 = 0.1\n",
    "high_thresh_canny_c10 = 0.25\n",
    "\n",
    "\n",
    "bordas_canny_c10 = feature.canny(image_float_g, sigma=sigma_canny_c10,\n",
    "                                 low_threshold=low_thresh_canny_c10,\n",
    "                                 high_threshold=high_thresh_canny_c10)\n",
    "\n",
    "plot_images_c5([image_float_g, bordas_canny_c10],\n",
    "               [\"Original\", f\"Canny Edges (s={sigma_canny_c10}, L={low_thresh_canny_c10:.2f}, H={high_thresh_canny_c10:.2f})\"],\n",
    "               cmaps=['gray','gray']) # plot_images_c5 is the corrected function"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "MTfucFIZHtkp",
    "outputId": "1115f9b7-79f8-4c9d-a464-8a92a7a6273f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interpreting the Results (Canny):\n",
    "\n",
    "* Original: Input image.\n",
    "* Canny Edges: Binary image with edges detected by Canny.\n",
    "* In general, Canny tends to produce thinner and better-connected edges than simple gradient thresholding.\n"
   ],
   "metadata": {
    "id": "O29kIDZx4Olf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exercise (Canny):\n",
    "\n",
    "1. Vary `sigma_canny_c10` (e.g., 0.5, 2.0, 3.0). How does this affect detected edges? What happens to noise and fine details?\n",
    "2. Adjust `low_thresh_canny_c10` and `high_thresh_canny_c10`. How do false positives and missed edges change?\n"
   ],
   "metadata": {
    "id": "p8n8liVl5YSe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Python - Simple Global Thresholding and Histogram (Practice)\n"
   ],
   "metadata": {
    "id": "fRMQpDAv-Hu0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Objective: Visualize the image histogram and apply a manually chosen global threshold.\n"
   ],
   "metadata": {
    "id": "2-2nPo8x-Ify"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How the Code Works:\n",
    "\n",
    "1. Histogram: `exposure.histogram(image_ubyte_g)` computes histogram of the 8-bit image.\n",
    "2. Manual Threshold: choose `limiar_manual_ubyte` and convert to float range when needed.\n",
    "3. Segmentation: creates a binary image from threshold comparison.\n"
   ],
   "metadata": {
    "id": "1_rIVCcO-KkP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Python Example: Simple Global Thresholding and Histogram\n",
    "print(\"\\n--- Practical Example: Simple Global Thresholding ---\")\n",
    "\n",
    "# Compute and plot the ubyte image histogram\n",
    "hist_original_c10, bins_orig_c10 = exposure.histogram(image_ubyte_g, nbins=256, source_range='image')\n",
    "\n",
    "# Choose a manual threshold by inspecting the histogram (value between 0-255)\n",
    "limiar_manual_ubyte = 80 # Example, adjust this value!\n",
    "# Convert to float image scale [0,1] if needed\n",
    "limiar_manual_float = limiar_manual_ubyte / 255.0\n",
    "\n",
    "# Apply threshold to float image\n",
    "img_limiarizada_manual = image_float_g > limiar_manual_float\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "axes[0].imshow(image_float_g, cmap='gray'); axes[0].set_title('Original'); axes[0].axis('off')\n",
    "\n",
    "axes[1].plot(bins_orig_c10, hist_original_c10, color='blue')\n",
    "axes[1].axvline(limiar_manual_ubyte, color='red', linestyle='dashed', linewidth=2)\n",
    "axes[1].set_title(f'Histogram and Manual Threshold ({limiar_manual_ubyte})')\n",
    "axes[1].set_xlabel('Gray Level'); axes[1].set_ylabel('Pixel Count')\n",
    "\n",
    "axes[2].imshow(img_limiarizada_manual, cmap='gray'); axes[2].set_title(f'Segmented (T={limiar_manual_ubyte})'); axes[2].axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "lkDlpynP4LB9",
    "outputId": "ec5f6afc-3c25-4993-c97f-513a5b68538b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exercise (Manual Thresholding):\n",
    "\n",
    "1. Observe the histogram of `image_ubyte_g` and identify a possible valley between peaks.\n",
    "2. Change `limiar_manual_ubyte` and compare segmentation quality.\n"
   ],
   "metadata": {
    "id": "NTTq74M6-sVQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Python - Otsu Method and Adaptive Thresholding (Practice)\n"
   ],
   "metadata": {
    "id": "dsPAKOe6CDhU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Objective: Apply Otsu's method for automatic global thresholding and an adaptive thresholding method.\n"
   ],
   "metadata": {
    "id": "F_dRXgJjCJC2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How the Code Works:\n",
    "\n",
    "1. Otsu Method:\n",
    "   * `filters.threshold_otsu(image_ubyte_g)`: automatically computes an optimal global threshold.\n",
    "   * `img_otsu = image_ubyte_g > limiar_otsu`.\n",
    "2. Adaptive Thresholding:\n",
    "   * `filters.threshold_local(...)` computes a local threshold per pixel neighborhood.\n",
    "   * Parameters `block_size_adapt` and `offset_adapt` control locality and bias.\n"
   ],
   "metadata": {
    "id": "eHgZqXg1CNxz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Python Example: Otsu Method and Adaptive Thresholding\n",
    "print(\"\\n--- Practical Example: Otsu and Adaptive Thresholding ---\")\n",
    "\n",
    "# Otsu Method (Global)\n",
    "limiar_otsu = filters.threshold_otsu(image_ubyte_g) # Computes optimal threshold\n",
    "img_otsu = image_ubyte_g > limiar_otsu          # Applies threshold\n",
    "\n",
    "# Local Adaptive Thresholding (e.g., using Gaussian neighborhood mean)\n",
    "# block_size must be odd and greater than 1\n",
    "block_size_adapt = 35 # Local neighborhood size. Adjust this value.\n",
    "offset_adapt = 0.02   # Offset to adjust local threshold. Adjust this value.\n",
    "# threshold_local returns a threshold image, one value per pixel.\n",
    "limiares_adaptativos = filters.threshold_local(image_float_g, block_size=block_size_adapt,\n",
    "                                             method='gaussian', offset=offset_adapt)\n",
    "img_adaptativa = image_float_g > limiares_adaptativos\n",
    "\n",
    "plot_images_c5([image_float_g, img_otsu, img_adaptativa],\n",
    "               [\"Original\", f\"Otsu (T={limiar_otsu})\", f\"Adaptive (block={block_size_adapt}, offs={offset_adapt})\"],\n",
    "               cmaps=['gray','gray','gray'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "id": "V1tsumTr-aHM",
    "outputId": "e4332c42-c9cb-42b5-b57d-aea6be1a232b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interpreting the Results (Otsu and Adaptive):\n",
    "\n",
    "1. Otsu: global separation based on histogram distribution.\n",
    "2. Adaptive: better handles nonuniform illumination and local contrast changes.\n"
   ],
   "metadata": {
    "id": "sp04DO73D3NV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exercise (Otsu and Adaptive):\n"
   ],
   "metadata": {
    "id": "1Ma16ZdzEGr7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. For adaptive thresholding, try different `block_size_adapt` (e.g., 15, 55, 101) and `offset_adapt` (e.g., -0.05, 0, 0.05). How do these parameters affect segmentation?\n",
    "2. Compare Otsu vs adaptive on this image. Which one is better and why?\n"
   ],
   "metadata": {
    "id": "FdHW8LSsEH8s"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Python - Region Growing (Conceptual/Simplified)\n"
   ],
   "metadata": {
    "id": "yMelBcBSIcUS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Objective: Illustrate the basic concept of seed-based region growing. A full implementation can be more complex, but this simulates the core idea.\n"
   ],
   "metadata": {
    "id": "fAZhNXVZIe3T"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How the Code Works:\n",
    "\n",
    "1. Seed and Similarity Threshold:\n",
    "   * `idx_linha_semente`, `idx_col_semente`: initial seed pixel.\n",
    "   * `limiar_similaridade_rg`: maximum intensity difference to include neighboring pixels.\n",
    "2. Queue-based expansion:\n",
    "   * Starts from seed and checks 8-connected neighbors.\n",
    "   * Adds neighbors that satisfy similarity criterion and are not visited.\n",
    "3. Output:\n",
    "   * Binary grown region mask and original image with seed marker.\n"
   ],
   "metadata": {
    "id": "Skg27w_lIiFb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Python Example: Region Growing (Simplified)\n",
    "print(\"\\n--- Practical Example: Region Growing (Simplified) ---\")\n",
    "from collections import deque # To use a queue\n",
    "\n",
    "# Use image_float_g and its dimensions M_g, N_g\n",
    "\n",
    "# Parameters for region growing\n",
    "# Choose a seed. For the brain image, a bright interior point works well.\n",
    "# Inspect image_float_g to choose a good seed.\n",
    "# Example (may need adjustment):\n",
    "idx_linha_semente = M_g // 2\n",
    "idx_col_semente = N_g // 2\n",
    "# Check if the initial seed is not too dark (background)\n",
    "if image_float_g[idx_linha_semente, idx_col_semente] < 0.1: # If it is too dark, try another\n",
    "    idx_linha_semente = M_g // 3\n",
    "    idx_col_semente = N_g // 2\n",
    "    if image_float_g[idx_linha_semente, idx_col_semente] < 0.1:\n",
    "         idx_linha_semente = M_g // 2 + 20; idx_col_semente = N_g //2 + 20\n",
    "\n",
    "\n",
    "valor_semente = image_float_g[idx_linha_semente, idx_col_semente]\n",
    "print(f\"Seed at ({idx_linha_semente},{idx_col_semente}) with value {valor_semente:.2f}\")\n",
    "\n",
    "limiar_similaridade_rg = 0.1 # Maximum intensity difference to be considered similar\n",
    "\n",
    "img_segmentada_rg = np.zeros_like(image_float_g, dtype=np.uint8)\n",
    "fila_rg = deque()\n",
    "\n",
    "if 0 <= valor_semente <= 1: # Ensure seed is valid\n",
    "    img_segmentada_rg[idx_linha_semente, idx_col_semente] = 1\n",
    "    fila_rg.append((idx_linha_semente, idx_col_semente))\n",
    "\n",
    "    # Process the queue\n",
    "    while fila_rg:\n",
    "        r_atual, c_atual = fila_rg.popleft()\n",
    "\n",
    "        # Check 8 neighbors\n",
    "        for dr in [-1, 0, 1]:\n",
    "            for dc in [-1, 0, 1]:\n",
    "                if dr == 0 and dc == 0:\n",
    "                    continue # Skip the current pixel itself\n",
    "\n",
    "                r_viz, c_viz = r_atual + dr, c_atual + dc\n",
    "\n",
    "                # Check image boundaries\n",
    "                if 0 <= r_viz < M_g and 0 <= c_viz < N_g:\n",
    "                    # Check if not visited and satisfies similarity criterion\n",
    "                    if img_segmentada_rg[r_viz, c_viz] == 0 and \\\n",
    "                       np.abs(image_float_g[r_viz, c_viz] - valor_semente) < limiar_similaridade_rg:\n",
    "                        # (Simple criterion: similarity to original seed)\n",
    "                        # (A more robust criterion would use the mean of the grown region)\n",
    "                        img_segmentada_rg[r_viz, c_viz] = 1\n",
    "                        fila_rg.append((r_viz, c_viz))\n",
    "else:\n",
    "    print(\"Invalid seed value or outside expected range.\")\n",
    "\n",
    "\n",
    "# Visualization\n",
    "img_original_com_semente = img_as_ubyte(image_float_g.copy())\n",
    "img_original_com_semente = cv2.cvtColor(img_original_com_semente, cv2.COLOR_GRAY2BGR)\n",
    "if 0 <= valor_semente <= 1: # Draw only if seed is valid\n",
    "    cv2.circle(img_original_com_semente, (idx_col_semente, idx_linha_semente), 5, (0,255,0), -1) # Seed at verde\n",
    "\n",
    "\n",
    "plot_images_c5([img_original_com_semente, img_segmentada_rg],\n",
    "               [\"Original with Seed\", f\"Grown Region (Seed at ({idx_linha_semente},{idx_col_semente}), T={limiar_similaridade_rg})\"],\n",
    "               cmaps=['gray','gray'], figsize=(10,5)) # cmap does not apply to img_original_com_semente if BGR"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "f8NsLq_EDu8W",
    "outputId": "519ad626-d2cd-44e5-9300-82c01a425b67"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interpreting the Results (Region Growing):\n",
    "\n",
    "* Original with Seed: shows where growth starts.\n",
    "* Grown Region: shows connected pixels similar to seed under chosen threshold.\n",
    "* Behavior depends strongly on seed location and similarity threshold.\n"
   ],
   "metadata": {
    "id": "dxfxWI6-LN-F"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exercise (Region Growing):\n",
    "\n",
    "1. Change `idx_linha_semente` and `idx_col_semente` to different image areas.\n",
    "2. Change `limiar_similaridade_rg` (e.g., 0.05, 0.15, 0.25).\n",
    "3. Observe under-segmentation vs over-segmentation behavior.\n"
   ],
   "metadata": {
    "id": "fqC8YQarLTTK"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "xzKqtS90LI34"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}