{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Initial Setup and Review (Run First)\n",
    "\n",
    "This initial block reloads the sample medical image (brain slice) and defines some helper functions and global variables (`M_c5`, `N_c5`, `P_c5`, `Q_c5`) that are used in the examples below.\n"
   ],
   "metadata": {
    "id": "EKwTEHkEoiOA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How the Code Works:\n",
    "\n",
    "* Imports: Loads the required libraries.\n",
    "* Image Loading: Loads `data.brain()` and selects a central slice (or uses `camera` as fallback).\n",
    "* Initial Definitions:\n",
    "  * `idft_process_extract`: helper for inverse DFT with padding removal.\n",
    "  * `plot_images_c5`: helper for displaying multiple images.\n",
    "* Degradation Model Review: prints the conceptual equations in spatial and frequency domains.\n"
   ],
   "metadata": {
    "id": "i_dZqFqtolsl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "id": "9RcdlDrsoa66",
    "outputId": "370c73a9-942e-4e01-bb94-422674fbfdb0"
   },
   "outputs": [],
   "source": [
    "# --- Required Imports ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data, img_as_float, img_as_ubyte, exposure, util, filters\n",
    "from scipy import ndimage\n",
    "from numpy.fft import fft2, ifft2, fftshift, ifftshift\n",
    "import time # Not actively used in these examples, but useful to keep\n",
    "\n",
    "# --- Load Medical Image and Define Global Variables ---\n",
    "try:\n",
    "    brain_volume = data.brain()\n",
    "    if brain_volume.ndim == 3:\n",
    "        slice_index = brain_volume.shape[0] // 2\n",
    "        image_gray_orig_c5 = brain_volume[slice_index, :, :]\n",
    "    elif brain_volume.ndim == 2:\n",
    "        image_gray_orig_c5 = brain_volume\n",
    "        slice_index = \"N/A (2D Image)\"\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected 'brain' image format.\")\n",
    "    print(f\"'brain' image (slice {slice_index if brain_volume.ndim == 3 else ''}) loaded for Ch. 5.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading 'brain': {e}. Using 'camera' as fallback.\")\n",
    "    image_gray_orig_c5 = data.camera()\n",
    "\n",
    "image_float_c5 = img_as_float(image_gray_orig_c5.copy())\n",
    "M_c5, N_c5 = image_float_c5.shape # Original dimensions\n",
    "P_c5, Q_c5 = 2*M_c5, 2*N_c5     # Padded dimensions\n",
    "\n",
    "# --- Helper Function for IDFT, Extraction, and Rescaling ---\n",
    "def idft_process_extract(G_centralizado, P_img, Q_img, M_orig, N_orig):\n",
    "    \"\"\"Applies ifftshift/ifft2, takes real part, removes padding, and rescales.\"\"\"\n",
    "    G_canto_dc = ifftshift(G_centralizado) # Move DC to the corner before IDFT\n",
    "    img_padded_spatial = ifft2(G_canto_dc).real\n",
    "    img_final = img_padded_spatial[0:M_orig, 0:N_orig] # Remove padding\n",
    "    return exposure.rescale_intensity(img_final, out_range=(0,1))\n",
    "\n",
    "# --- Helper Plot Function (already defined earlier, repeated here for self-contained execution) ---\n",
    "def plot_images_c5(images, titles, cmaps=None, rows=1, cols=None, figsize=(15,5)):\n",
    "    num_images = len(images)\n",
    "    if cols is None:\n",
    "        cols = (num_images + rows - 1) // rows\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize, squeeze=False)\n",
    "    axes_flat = axes.ravel()\n",
    "    if cmaps is None: cmaps_list = ['gray'] * num_images\n",
    "    elif isinstance(cmaps, str): cmaps_list = [cmaps] * num_images\n",
    "    else:\n",
    "        cmaps_list = list(cmaps)\n",
    "        if len(cmaps_list) < num_images: cmaps_list.extend(['gray']*(num_images-len(cmaps_list)))\n",
    "    for i in range(len(axes_flat)):\n",
    "        if i < num_images:\n",
    "            img, title, cmap = images[i], titles[i], cmaps_list[i]\n",
    "            axes_flat[i].imshow(img, cmap=cmap if img.ndim==2 else None); axes_flat[i].set_title(title); axes_flat[i].axis('off')\n",
    "        else: axes_flat[i].axis('off')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# Degradation Model (Conceptual Review)\n",
    "print(\"\\n--- Degradation/Restoration Model (Review) ---\")\n",
    "print(\"Spatial Domain: g(x,y) = h(x,y) * f(x,y) + η(x,y)\")\n",
    "print(\"Frequency Domain: G(u,v) = H(u,v)F(u,v) + N(u,v)\")\n",
    "print(\"f: original, h/H: degradation, η/N: noise, g/G: observed\")\n",
    "\n",
    "plot_images_c5([image_float_c5], [\"Original Test Image (f)\"], cmaps=['gray'], figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The text output confirms the degradation model.\n",
    "\n",
    "The displayed image is the MRI slice (or the `camera` image as fallback), which will be used as `f(x,y)` in the restoration examples.\n"
   ],
   "metadata": {
    "id": "iStLROM0pUlA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5.4 Periodic Noise Reduction by Frequency-Domain Filtering\n"
   ],
   "metadata": {
    "id": "8FD5Givbye6a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This example simulates adding periodic (sinusoidal) noise to an image and then applies a notch filter in the frequency domain to remove it.\n"
   ],
   "metadata": {
    "id": "X5VHxW-gyhtY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Periodic Noise Addition: A sinusoidal noise with `num_noise_cycles` cycles along image height `M_c5` is added to `image_float_c5`.\n",
    "2. DFT and Spectrum: The noisy image is padded and transformed into the frequency domain.\n",
    "3. Notch Filter Construction: Two Gaussian notches are placed at the expected noise peak locations.\n",
    "4. Filtering and IDFT: The filter is applied in frequency domain, then transformed back to spatial domain.\n"
   ],
   "metadata": {
    "id": "ibiXKkZTyxzq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 5.4 Periodic Noise Reduction\n",
    "\n",
    "print(\"\\n--- Example 5.4: Periodic Noise Reduction ---\")\n",
    "# 1. Add sinusoidal periodic noise to the original image\n",
    "img_with_periodic_noise = image_float_c5.copy()\n",
    "num_noise_cycles = 20 # Number of vertical noise cycles\n",
    "noise_period_px_5_4 = M_c5 / num_noise_cycles\n",
    "noise_amplitude_5_4 = 0.3\n",
    "for r in range(M_c5):\n",
    "    img_with_periodic_noise[r,:] += noise_amplitude_5_4 * np.cos(2 * np.pi * r / noise_period_px_5_4)\n",
    "img_with_periodic_noise = np.clip(img_with_periodic_noise, 0, 1)\n",
    "\n",
    "# 2. Prepare noisy image for DFT (padding)\n",
    "fp_noisy_notch_pad = np.zeros((P_c5, Q_c5), dtype=float)\n",
    "fp_noisy_notch_pad[0:M_c5, 0:N_c5] = img_with_periodic_noise\n",
    "\n",
    "# 3. Compute DFT and center the spectrum\n",
    "Fp_noisy_notch_centered = fftshift(fft2(fp_noisy_notch_pad))\n",
    "noisy_spectrum_vis = np.log1p(np.abs(Fp_noisy_notch_centered))\n",
    "\n",
    "# 4. Create frequency grids (U for vertical, V for horizontal in the spectrum)\n",
    "II_filt_5_4, JJ_filt_5_4 = np.indices((P_c5, Q_c5))\n",
    "U_map_filt_5_4 = II_filt_5_4 - P_c5//2\n",
    "V_map_filt_5_4 = JJ_filt_5_4 - Q_c5//2\n",
    "\n",
    "# 5. Locate noise peaks\n",
    "kv_noise_peak_5_4 = num_noise_cycles * (P_c5 / M_c5) # Peak position on U_map axis\n",
    "\n",
    "# 6. Notch Filter Construction\n",
    "sigma_notch_5_4 = P_c5 * 0.01 # Notch width (e.g., 1% of P). Adjust as needed.\n",
    "H_filtro_notch_5_4 = np.ones((P_c5, Q_c5), dtype=float)\n",
    "\n",
    "if kv_noise_peak_5_4 != 0:\n",
    "    # Peak 1: (U_map = +kv_pico_ruido, V_map = 0)\n",
    "    D1_sq = (U_map_filt_5_4 - kv_noise_peak_5_4)**2 + (V_map_filt_5_4 - 0)**2\n",
    "    H_filtro_notch_5_4 *= (1 - np.exp(-D1_sq / (2 * sigma_notch_5_4**2)))\n",
    "    # Peak 2: (U_map = -kv_pico_ruido, V_map = 0)\n",
    "    D2_sq = (U_map_filt_5_4 + kv_noise_peak_5_4)**2 + (V_map_filt_5_4 - 0)**2\n",
    "    H_filtro_notch_5_4 *= (1 - np.exp(-D2_sq / (2 * sigma_notch_5_4**2)))\n",
    "\n",
    "# 7. Apply notch filter\n",
    "G_notch_filtered_centered = H_filtro_notch_5_4 * Fp_noisy_notch_centered\n",
    "\n",
    "# 8. IDFT and post-processing\n",
    "img_notch_filtered = idft_process_extract(G_notch_filtered_centered, P_c5, Q_c5, M_c5, N_c5)\n",
    "\n",
    "# Visualization\n",
    "plot_images_c5([img_with_periodic_noise, noisy_spectrum_vis, H_filtro_notch_5_4, img_notch_filtered],\n",
    "               [f\"With Periodic Noise ({num_noise_cycles} cycles)\", \"Noisy Spectrum\", f\"Notch Filter (sigma={sigma_notch_5_4:.1f})\", \"Notch Result\"],\n",
    "               rows=2, cols=2, cmaps=['gray','viridis','viridis','gray'], figsize=(10,10))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KEwWKmE8tlKf",
    "outputId": "b34a79a1-67f5-4276-df49-60f9b4e1022e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Image with Periodic Noise: The first image shows horizontal stripe-like sinusoidal artifacts.\n",
    "* Noisy Spectrum: The second image shows bright symmetric peaks away from the center, corresponding to the periodic noise.\n",
    "* Notch Filter: The third image shows attenuation at exactly those peak locations.\n",
    "* Notch Result: The fourth image should show reduced periodic artifacts with better overall quality.\n"
   ],
   "metadata": {
    "id": "hhRD5-_zzcZ_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5.5 Linear and Position-Invariant Degradations\n"
   ],
   "metadata": {
    "id": "eklOKvnFp3Rl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This section is mainly conceptual and provides the foundation for restoration filters that handle blur. There is no practical filtering example here.\n"
   ],
   "metadata": {
    "id": "RWcp2JkKqBGc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How the Code Works (Conceptual):\n",
    "\n",
    "It reviews that if degradation `h(x,y)` is Linear and Position-Invariant (LPI), then degraded image `g(x,y)` is given by convolution with the original `f(x,y)` (ignoring noise), and multiplication in frequency domain.\n"
   ],
   "metadata": {
    "id": "KAFr03_JqCIC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 5.5 Linear and Position-Invariant Degradations (Conceptual)\n",
    "print(\"\\n--- Section 5.5: Linear and Position-Invariant Degradations (LPI) ---\")\n",
    "print(\"This section is fundamentally theoretical, establishing that if degradation h(x,y) is LPI,\")\n",
    "print(\"then g(x,y) = h(x,y) * f(x,y) (without noise).\")\n",
    "print(\"In frequency domain: G(u,v) = H(u,v)F(u,v).\")\n",
    "print(\"This model is the basis for the deconvolution filters shown next.\")\n",
    "# There is no specific code to run here; this cell reinforces the concept."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWIaR2HdqJ58",
    "outputId": "874c245c-6fec-414d-e1e1-30c08e2e3cd1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "5.6 Estimating the Degradation Function H\n"
   ],
   "metadata": {
    "id": "jGBsOH-ip4EX"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To restore an image degraded by blur, we need an estimate of the degradation function `H(u,v)` (or its spatial PSF `h(x,y)`).\n"
   ],
   "metadata": {
    "id": "zaXaHEfgqOIS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Motion PSF Simulation:\n",
    "* `L_mov = 20`: motion blur length in pixels.\n",
    "* `theta_mov = 0`: horizontal motion angle.\n",
    "* A motion PSF is created and then padded/rolled to match DFT convention.\n",
    "\n",
    "2. `H(u,v)` Estimation:\n",
    "* The FFT of padded PSF gives `H_motion_not_centered` (DC at corner).\n",
    "* `fftshift` is used for visualization.\n",
    "\n",
    "3. Degradation Simulation:\n",
    "* Original image (padded) is multiplied by `H(u,v)` in frequency domain.\n",
    "* Inverse FFT gives a blurred image (motion blur).\n"
   ],
   "metadata": {
    "id": "UDSqAUw0qT-Z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# M_c5, N_c5 are the dimensions of the original image (ex: image_float_c5)\n",
    "# P_c5, Q_c5 are the padded dimensions (ex: 2*M_c5, 2*N_c5)\n",
    "\n",
    "# 1. Create a zero matrix with padded dimensions (P_c5 x Q_c5)\n",
    "fp_para_filtragem = np.zeros((P_c5, Q_c5), dtype=float)\n",
    "\n",
    "# 2. Copy the original image to the top-left corner of this larger matrix\n",
    "fp_para_filtragem[0:M_c5, 0:N_c5] = image_float_c5"
   ],
   "metadata": {
    "id": "xvSKbKsDt9oz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 5.6 Estimating the Degradation Function H\n",
    "\n",
    "print(\"\\n--- Example 5.6: Simulation of a Motion PSF and its H(u,v) ---\")\n",
    "# 1. Simulate a horizontal motion-blur PSF\n",
    "L_mov = 21 # Motion length (pixels), odd for a defined center\n",
    "psf_motion = np.zeros((L_mov, L_mov), dtype=float)\n",
    "# Create a horizontal line at PSF center\n",
    "psf_motion[L_mov//2, :] = 1.0\n",
    "psf_motion /= np.sum(psf_motion) # Normaliza a PSF\n",
    "\n",
    "# 2. Compute H(u,v) from PSF (with padding and centering for visualization)\n",
    "psf_motion_padded = np.zeros((P_c5, Q_c5), dtype=float)\n",
    "# Place PSF in top-left corner for DFT (convolution origin)\n",
    "# However, to keep H(u,v) real after shift (if PSF is symmetric),\n",
    "# a PSF deve estar centralizada no array antes do fftshift(fft2(...))\n",
    "# place PSF in the corner and shift H(u,v) for visualization.\n",
    "# For degradation computation G = FH, H must follow the same ordering as F.\n",
    "# If F has DC at corner, H must too. If F has centered DC, H must too.\n",
    "\n",
    "# Standardization: PSF origin at corner (0,0) of PxQ array\n",
    "# The PSF center (pixel L_mov//2, L_mov//2) maps to (0,0) in PxQ after roll.\n",
    "# Alternatively, place the PSF directly at corner (0,0) of PxQ array.\n",
    "# psf_motion_padded[0:L_mov, 0:L_mov] = psf_motion # PSF at corner\n",
    "\n",
    "# For frequency-domain convolution G = F*H to work correctly,\n",
    "# H must be the DFT of PSF h(x,y) with origin at pixel (0,0) of the matrix.\n",
    "# A PSF que criamos (psf_motion) tem seu \"center\" em L_mov//2.\n",
    "# We place the psf_motion center at (0,0) of psf_motion_padded,\n",
    "# allowing wraparound, which is correct for DFT/convolution.\n",
    "psf_motion_padded_rolled = np.zeros((P_c5, Q_c5), dtype=float)\n",
    "r_offset, c_offset = L_mov//2, L_mov//2\n",
    "for r_psf in range(L_mov):\n",
    "    for c_psf in range(L_mov):\n",
    "        # Map (r_psf, c_psf) from PSF to PxQ positions with (0,0) as PSF center\n",
    "        # (r_psf - r_offset) mod P_c5 etc.\n",
    "        idx_r_pad = (r_psf - r_offset + P_c5) % P_c5\n",
    "        idx_c_pad = (c_psf - c_offset + Q_c5) % Q_c5\n",
    "        psf_motion_padded_rolled[idx_r_pad, idx_c_pad] = psf_motion[r_psf, c_psf]\n",
    "\n",
    "H_motion_not_centered = fft2(psf_motion_padded_rolled) # DC at corner\n",
    "H_motion_centered_vis = fftshift(H_motion_not_centered) # centered DC for visualization\n",
    "\n",
    "# 3. Simulate Degradation on Original Image\n",
    "# fp_para_filtragem was defined in 4.7/4.8 as padded image_float\n",
    "F_img_original_padded_not_centered = fft2(fp_para_filtragem) # DC at corner\n",
    "\n",
    "# G = F * H (both with DC at corner)\n",
    "G_motion_degraded_not_centered = F_img_original_padded_not_centered * H_motion_not_centered\n",
    "img_motion_degraded_padded = ifft2(G_motion_degraded_not_centered).real\n",
    "img_motion_degraded = exposure.rescale_intensity(img_motion_degraded_padded[0:M_c5, 0:N_c5], out_range=(0,1))\n",
    "\n",
    "# Visualization\n",
    "plot_images_c5([psf_motion, np.log1p(np.abs(H_motion_centered_vis)), image_float_c5, img_motion_degraded],\n",
    "               [f\"Motion PSF ({L_mov}px horiz.)\", \"H_mov Spectrum (Log)\", \"Original Image\", \"Motion-Degraded Image\"],\n",
    "               rows=2, cols=2, cmaps=['gray','viridis','gray','gray'], figsize=(10,10))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e8wqpxq5xEZZ",
    "outputId": "2121d688-2446-40af-b6e6-335d3e1d401f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interpreting Results (5.6):\n",
    "\n",
    "* Motion PSF: The first image shows the PSF that simulates horizontal motion blur.\n",
    "* `|H(u,v)|` Spectrum: The second image shows periodic nulls/attenuations where frequencies are suppressed by motion blur.\n",
    "* Degraded Image: The third image shows characteristic directional blur from linear motion.\n"
   ],
   "metadata": {
    "id": "jEH0m3XnxPcF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5.7 Inverse Filtering\n"
   ],
   "metadata": {
    "id": "QB5ZsV4BxXhJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inverse filtering attempts to reverse degradation by dividing the degraded image DFT by the degradation function DFT `H(u,v)`. This section shows direct inverse filtering and truncated inverse filtering.\n"
   ],
   "metadata": {
    "id": "t4s_ittQxZvM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Degraded Image and `H(u,v)`: Reuses `img_motion_degraded` and `H_motion_not_centered` from the previous example; adds Gaussian noise to make the restoration challenge realistic.\n",
    "2. Direct Inverse Filtering: Computes `F_hat = G / H` with epsilon for numerical stability.\n",
    "3. Truncated Inverse Filtering (Pseudo-inverse): Uses inverse filtering only where `|H|` is above a threshold.\n",
    "4. Comparison: Plots degraded input, direct inverse result, and truncated inverse result.\n"
   ],
   "metadata": {
    "id": "1YuwM4m3xcuM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 5.7 Inverse Filtering\n",
    "\n",
    "print(\"\\n--- Example 5.7: Inverse Filtering ---\")\n",
    "# Use the motion-degraded image and H(u,v) from previous example (5.6)\n",
    "# Assumes variables image_float_c5, M_c5, N_c5, P_c5, Q_c5,\n",
    "# H_motion_not_centered (DFT of motion PSF, DC at corner),\n",
    "# and img_motion_degraded (blurred image without extra noise) are defined from Example 5.6.\n",
    "\n",
    "# Add a bit of noise to the motion-degraded image\n",
    "sigma_noise_inv_5_7 = 0.01\n",
    "img_motion_degraded_ruidosa_5_7 = util.random_noise(img_motion_degraded, mode='gaussian', var=sigma_noise_inv_5_7**2)\n",
    "img_motion_degraded_ruidosa_5_7 = np.clip(img_motion_degraded_ruidosa_5_7, 0, 1)\n",
    "\n",
    "# DFT of degraded noisy image (with implicit padding in PxQ dimensions)\n",
    "fp_degraded_noisy_5_7 = np.zeros((P_c5, Q_c5))\n",
    "fp_degraded_noisy_5_7[0:M_c5, 0:N_c5] = img_motion_degraded_ruidosa_5_7\n",
    "G_degraded_noisy_not_cent_5_7 = fft2(fp_degraded_noisy_5_7) # DC at corner\n",
    "\n",
    "# Define epsilon\n",
    "epsilon = 1e-8 # Small constant to avoid division by zero\n",
    "\n",
    "# 1. Direct Inverse Filtering\n",
    "# H_motion_not_centered is the PSF DFT (HxQ) with DC at corner\n",
    "F_hat_inverse_direct_not_cent_5_7 = G_degraded_noisy_not_cent_5_7 / (H_motion_not_centered + epsilon)\n",
    "img_rest_inverse_direct_padded_5_7 = ifft2(F_hat_inverse_direct_not_cent_5_7).real\n",
    "img_rest_inverse_direct_5_7 = exposure.rescale_intensity(img_rest_inverse_direct_padded_5_7[0:M_c5, 0:N_c5], out_range=(0,1))\n",
    "\n",
    "# 2. Truncated Inverse Filtering (Pseudo-inverse)\n",
    "H_abs_not_cent_5_7 = np.abs(H_motion_not_centered)\n",
    "H_truncation_threshold_5_7 = H_abs_not_cent_5_7.max() * 0.05 # e.g., 5% of max |H|\n",
    "\n",
    "F_hat_inverse_trunc_not_cent_5_7 = np.zeros_like(G_degraded_noisy_not_cent_5_7, dtype=complex)\n",
    "H_valid_mask_5_7 = H_abs_not_cent_5_7 > H_truncation_threshold_5_7\n",
    "\n",
    "# Avoid divide-by-zero warnings even with epsilon by checking mask first\n",
    "# and ensuring H_motion_not_centered[H_valid_mask_5_7] is not zero.\n",
    "# Epsilon already helps, but this check is safer.\n",
    "H_valid = H_motion_not_centered[H_valid_mask_5_7]\n",
    "G_valid = G_degraded_noisy_not_cent_5_7[H_valid_mask_5_7]\n",
    "F_hat_inverse_trunc_not_cent_5_7[H_valid_mask_5_7] = G_valid / (H_valid + epsilon)\n",
    "\n",
    "\n",
    "img_rest_inverse_trunc_padded_5_7 = ifft2(F_hat_inverse_trunc_not_cent_5_7).real\n",
    "img_rest_inverse_trunc_5_7 = exposure.rescale_intensity(img_rest_inverse_trunc_padded_5_7[0:M_c5, 0:N_c5], out_range=(0,1))\n",
    "\n",
    "# Visualization\n",
    "plot_images_c5([img_motion_degraded_ruidosa_5_7, img_rest_inverse_direct_5_7, img_rest_inverse_trunc_5_7],\n",
    "               [\"Motion-Degraded + Noise\", \"Direct Inverse Restoration\", f\"Truncated Inverse Restoration (limiar={H_truncation_threshold_5_7:.2e})\"],\n",
    "               cmaps=['gray','gray','gray'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "EzSxJlluq8-E",
    "outputId": "c9f54711-9d9c-4e4f-bfd4-2f898e9c34dd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Degraded by Motion + Noise: Input image for restoration.\n",
    "* Direct Inverse Restoration: Usually amplifies noise strongly, especially where `|H|` is close to zero.\n",
    "* Truncated Inverse Restoration: Generally more stable by avoiding inversion where `H` is too small, reducing severe artifacts.\n"
   ],
   "metadata": {
    "id": "mwE2hQ5ZrJmA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5.8 Wiener Filtering\n"
   ],
   "metadata": {
    "id": "YFdNffsxrPFM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wiener filtering is a statistical restoration approach that minimizes mean squared error between original and restored images.\n"
   ],
   "metadata": {
    "id": "XtCSUsrZrRQ5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Inputs:\n",
    "* `G_degradada_ruidosa_nao_cent`: DFT of degraded noisy image (DC at corner).\n",
    "* `H_motion_not_centered`: DFT of motion PSF.\n",
    "\n",
    "2. Wiener Filter Equation:\n",
    "* Uses `F_hat = [H* / (|H|^2 + K)] * G`, where `K` approximates noise-to-signal power ratio.\n",
    "\n",
    "3. Output:\n",
    "* Reconstructs restored image and compares with truncated inverse filtering.\n"
   ],
   "metadata": {
    "id": "QSxLFkenrSiD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 5.8 Wiener Filtering\n",
    "\n",
    "print(\"\\n--- Example 5.8: Wiener Filtering ---\")\n",
    "# Reuse G_degraded_noisy_not_cent_5_7 (DFT da imagem degradada+noise, DC at corner) do Example 5.7\n",
    "# Reuse H_motion_not_centered (DFT of PSF, DC at corner) do Example 5.6\n",
    "\n",
    "# Define epsilon\n",
    "epsilon = 1e-8 # Small constant to avoid division by zero\n",
    "\n",
    "# K parameter for Wiener filter (approximation of Sn(u,v)/Sf(u,v))\n",
    "K_wiener_5_8 = 0.01 # Tune this value experimentally (ex: 0.1, 0.01, 0.001)\n",
    "\n",
    "# Wiener filter components (Eq. 5.8-7: F_hat = [H* / (|H|^2 + Sn/Sf)] * G )\n",
    "# Sn/Sf is approximated by K.\n",
    "H_conj_wiener_5_8 = np.conj(H_motion_not_centered)\n",
    "H_mag_sq_wiener_5_8 = np.abs(H_motion_not_centered)**2\n",
    "\n",
    "# The K_wiener_5_8 term in denominator prevents division by zero when H_mag_sq_wiener_5_8 is zero.\n",
    "Wiener_filter_active_part_5_8 = H_conj_wiener_5_8 / (H_mag_sq_wiener_5_8 + K_wiener_5_8 + epsilon)\n",
    "F_hat_wiener_not_cent_5_8 = Wiener_filter_active_part_5_8 * G_degraded_noisy_not_cent_5_7\n",
    "\n",
    "# IDFT, remove padding, and rescale\n",
    "# (Assuming idft_process_extract was defined in the Initial Setup cell)\n",
    "img_rest_wiener_padded_5_8 = ifft2(F_hat_wiener_not_cent_5_8).real\n",
    "img_rest_wiener_5_8 = exposure.rescale_intensity(img_rest_wiener_padded_5_8[0:M_c5, 0:N_c5], out_range=(0,1))\n",
    "\n",
    "# Visualization\n",
    "# Reuse img_rest_inverse_trunc_5_7 for comparison\n",
    "plot_images_c5([img_motion_degraded_ruidosa_5_7, img_rest_inverse_trunc_5_7, img_rest_wiener_5_8],\n",
    "               [\"Motion-Degraded + Noise\", \"Truncated Inverse Restoration (ref.)\", f\"Wiener Restoration (K={K_wiener_5_8})\"],\n",
    "               cmaps=['gray','gray','gray'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "g-GdPNxGphu9",
    "outputId": "51c80ba2-6ecc-40db-c0a6-9f2459637b79"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Degraded by Motion + Noise: Input image.\n",
    "* Truncated Inverse Restoration (ref.): Reference from previous section.\n",
    "* Wiener Restoration: Usually achieves a better balance between deblurring and noise suppression.\n"
   ],
   "metadata": {
    "id": "hbwFt2AftS1r"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "SAhbJycMtQAe"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}